{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T18:52:38.020612Z",
     "start_time": "2024-08-08T18:52:35.364016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in c:\\users\\user\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\anaconda3\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from accelerate) (2.3.1+cu118)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "Using cached accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "Installing collected packages: accelerate, evaluate\n",
      "Successfully installed accelerate-0.33.0 evaluate-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7915feb71280f6e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T18:53:45.668440Z",
     "start_time": "2024-08-08T18:53:45.197651Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9dff107f7c444818c9fbc3edb797622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588e476cce634515a388ab7a71cc34b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0a372c8c184e7d96cfb47351f2e92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ac2c2576f54b7898134b5954a4e8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b06b32d1c800f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998044371604919}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"We are very happy to show you the Transformers library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75815ba-8546-4f72-be58-31bf9324eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n"
     ]
    }
   ],
   "source": [
    "results = classifier([\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"])\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab9223f-925c-4c44-80a8-df0e6074f2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be102e7a9ea4741a103b6d94e2766a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-base-960h. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c5f0333c364daaa0c132831a2ac196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b35fe070f54965a62646aebf921659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b1d79c923e4df08d2edde2c6a2e5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c0d6afb29f4336badd0582ba4da05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224706316a6d40f3aa3a86d52159cbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speeh = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1400514-9ac9-4252-a65c-846a530ce1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soundfile) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.21)\n",
      "Downloading soundfile-0.12.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 660.6 kB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.3/1.0 MB 2.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 0.7/1.0 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 397.2 kB/s eta 0:00:00\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.12.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471ce5d63e90497194d83605e50e1950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "!pip install soundfile\n",
    "import soundfile\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15259aa0-9271-4971-9bea-466071115741",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=speeh.feature_extractor.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06dd062f-0861-40ee-9ebc-5423c0dd85ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (0.59.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.4.0-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (23.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.2.2)\n",
      "Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "   ---------------------------------------- 0.0/260.1 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/260.1 kB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 153.6/260.1 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 260.1/260.1 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB ? eta 0:00:00\n",
      "Downloading soxr-0.4.0-cp311-cp311-win_amd64.whl (184 kB)\n",
      "   ---------------------------------------- 0.0/184.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 184.7/184.7 kB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: soxr, audioread, pooch, librosa\n",
      "Successfully installed audioread-3.0.1 librosa-0.10.2.post1 pooch-1.8.2 soxr-0.4.0\n",
      "['I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT', \"FONDERING HOW I'D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE\", \"I I'D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I'M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I'M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS\", 'HOW DO I FURN A JOINA COUT']\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa\n",
    "import librosa\n",
    "result = speeh(dataset[:4][\"audio\"])\n",
    "print([d[\"text\"] for d in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642462bb-1431-47f4-acde-cc6bdd57d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3403e22f-0cfb-48b0-99e0-248194219733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbe781d06fc46fa83582a2d5aa336c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--nlptown--bert-base-multilingual-uncased-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be14041d5bf46ca8aefc2abe69beb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/669M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce0cae23d16457fb0e5edf09b9cb1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbdcede9ceb4dd3b6f3e84611b1eb2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/872k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf4af9f793c4d94bef03cca7f78a1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74853112-8fd7-44ee-ae65-ba98f8d92ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "result = classifier(\"Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fb48e2d-53a8-4df2-9819-f329f647cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb72e910-474b-4b32-b644-4c4fb50d5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the 🤗 Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "239fefa0-5464-4c60-84a2-51867f8052bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the 🤗 Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "166b96a3-cb9c-44d3-9a04-ee7e10f2c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cafc3e70-3f77-475f-8bbb-0e1a3f19aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "831251b4-b0fa-4584-974a-91ea01ca2156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a93ae03b-19a8-48f5-8332-0f2bbe739ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7357733d-1cec-4039-a6c8-6f516d719f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35965733-6afc-45ce-a71c-bb82256d27e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d102ab318ce451da34d2d3db0fe2d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b09681c5-74fb-4876-95eb-ee186c4238de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "my_model = AutoModel.from_config(my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95f4df3d-57ec-46db-b72c-2e85c30df5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6a83f067074f9cb6cc580e0a4a5a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4fb96a4-37e3-424a-a075-dbb5c73f29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"path/to/save/folder/\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e16e74f-1462-4fa6-ac45-15fdd8798aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59927cf2f8b4ccfab95134acb41f28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40486af27aef425da0ba6ddb49d5d019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36bcbe677e9240048e46a4ffa139279a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "820f8ec8-d800-41d6-af3a-d1c70981ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ea0f92513f4b08bbcee77a31094fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014a2fffb5854392891c057ff961d2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/699k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b8f328b20841b1afad88868ebfa825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316e98c6f461445c861e13f53658cd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10725604c2644e4ba71a09902157b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a15450799b4484683f5b6ea24146817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d10e59bb9149af880c0373defd2567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # doctest: +IGNORE_RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bbbff99-20a6-40da-99fc-7b2617508057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    return tokenizer(dataset[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "efc0e840-d452-47e7-802a-0c66a3d6d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e963e38ae0044bb81b4da19ebbfc9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f101318cbce14b62b297d49c70a3e554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be46491676f346e69b21f31214499b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23f776b9-4a1a-478b-893a-09d78961d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d24197e-dcc0-4e44-b2f4-b15114b610f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")  # doctest: +SKIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "275e7e64-8ac7-4e39-96ca-be047676c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2134' max='2134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2134/2134 01:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.449700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.269100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2134, training_loss=0.3367795166616252, metrics={'train_runtime': 98.186, 'train_samples_per_second': 173.752, 'train_steps_per_second': 21.734, 'total_flos': 195974132394480.0, 'train_loss': 0.3367795166616252, 'epoch': 2.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db537fce-2b17-46e4-a1f0-c849ca763841",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
